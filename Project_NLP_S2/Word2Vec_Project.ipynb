{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdjamina/M1_TALA410A_NLP/blob/main/Project_NLP_S2/Word2Vec_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/armandstrickernlp/NLP_Inalco/main/Semester2/Project_sem2/shakespeare.txt"
      ],
      "metadata": {
        "id": "yKaeeBZ1EUkA",
        "outputId": "e9f1df95-6278-4adf-ac5c-89436c2c1f58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yKaeeBZ1EUkA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-21 05:22:48--  https://raw.githubusercontent.com/armandstrickernlp/NLP_Inalco/main/Semester2/Project_sem2/shakespeare.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 306996 (300K) [text/plain]\n",
            "Saving to: ‘shakespeare.txt’\n",
            "\n",
            "shakespeare.txt     100%[===================>] 299.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-05-21 05:22:48 (10.4 MB/s) - ‘shakespeare.txt’ saved [306996/306996]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6eed90c-6c75-4d4d-8e9c-d26ef97f517f",
      "metadata": {
        "id": "b6eed90c-6c75-4d4d-8e9c-d26ef97f517f"
      },
      "source": [
        "# Word2Vec : Creating Word Embeddings with Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf0eeec-d3ec-4c2c-897c-0bbdf3066151",
      "metadata": {
        "id": "6cf0eeec-d3ec-4c2c-897c-0bbdf3066151"
      },
      "source": [
        "References : \n",
        "* https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\n",
        "* https://www.coursera.org/learn/probabilistic-models-in-nlp/home/week/4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac9c73c-640c-4a62-aa30-24405d784556",
      "metadata": {
        "id": "7ac9c73c-640c-4a62-aa30-24405d784556"
      },
      "source": [
        "## Why do we need word embeddings ?\n",
        "\n",
        "Before thinking about word embeddings, when doing NLP, we are interested in being able to transform sentences or words into numeric representations, to then feed them to our algorithms and perform predictions.  Some simple methods of doing so include using term frequencies or n-grams among other things (counting the number of times a word appears in positive tweets vs. negative tweets for example)...  While these can work quite well in some cases, sentences are essentially represented as \"Bags of Words\", meaning a lot of information is lost : sentence structure, semantics, what the usual context for a word is (the word *cat* for example may be frequently accompanied by *a* or *the* on the left since it's a noun).  \n",
        "\n",
        "So how can we find more expressive numeric representations ?  This motivated NLP researchers to create more sophisticated word representations, known as *word embeddings*.  These are *dense* vectors (vs. *sparse* vectors, vectors with many dimensions where most of the values are 0s) and are now fundamental to any machine learning algorithm in NLP."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85fd423-1218-42b6-9045-f83f4c064fff",
      "metadata": {
        "tags": [],
        "id": "f85fd423-1218-42b6-9045-f83f4c064fff"
      },
      "source": [
        "## What principle do these word embeddings rely on ?\n",
        "\n",
        "Creating word embeddings relies on the idea that \"You shall know a word by the company it keeps\" (Firth, 1957). In [distributional semantics](https://en.wikipedia.org/wiki/Distributional_semantics#Distributional_Hypothesis), the distributional hypothesis tells us that words which occur and are used in the same context are semantically similar to one another.  The word vectors (embeddings) created take into account this contextual information, and the resulting vectors for words that have *similar contexts* end up in the same area of the vector space :\n",
        "\n",
        "<img src='https://github.com/armandstrickernlp/NLP_Inalco/blob/main/Semester2/Project_sem2/vector_space_example.jpg?raw=1'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c82bb15-1ff2-42d1-8f68-fed1e9386c41",
      "metadata": {
        "id": "9c82bb15-1ff2-42d1-8f68-fed1e9386c41"
      },
      "source": [
        "## The Word2Vec Model\n",
        "\n",
        "This model was created by Google in 2013 and is a predictive deep learning based model :  given neighboring words, the neural network has to *predict* the word to be found at the center of the context given (this is only one of the possible architectures).\n",
        "\n",
        "\n",
        "Essentially, this model can leverage raw text (no annotations needed), create a vocabulary of possible words and generate dense word embeddings for each word. We can even specify the size of the word embedding vectors, which makes the dimensionality of the vectors much lower than the high-dimensional sparse vectors built using traditional Bag of Words models.\n",
        "\n",
        "The model architecture we will be looking at is called the **Continuous Bag of Words Model**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff704030-bc14-4be7-b0a6-c793005c3d11",
      "metadata": {
        "id": "ff704030-bc14-4be7-b0a6-c793005c3d11"
      },
      "source": [
        "## The Continuous Bag of Words Model (CBOW) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89ba3bf7-15d1-4113-809f-f24416957de4",
      "metadata": {
        "id": "89ba3bf7-15d1-4113-809f-f24416957de4"
      },
      "source": [
        "To create word embeddings, you need a corpus and a learning algorithm. The *by-product* of this task would be a set of word embeddings. In the case of the continuous bag-of-words model, the objective of the task is to predict a missing word based on the surrounding words.\n",
        "\n",
        "<div style='text-align:center;'><img src='https://github.com/armandstrickernlp/NLP_Inalco/blob/main/Semester2/Project_sem2/Embedding_method.png?raw=1'/></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f7205a-3ac5-4ad7-84e3-b170b02ff3c8",
      "metadata": {
        "id": "73f7205a-3ac5-4ad7-84e3-b170b02ff3c8"
      },
      "source": [
        "The CBOW model architecture tries to predict the current target word (the center word) based on context words (the surrounding words). Let's take a simple example :\n",
        "> **“the quick brown fox jumps over the lazy dog”**.\n",
        "\n",
        "The sentence will be transformed into a series of examples for the model to train on : each example will consist of a (context_window, target_word) tuple.  Considering a context window of size $C=2$ (2 words to the left, 2 to the right, so 4 total) we would obtain :\n",
        "> Ex. 1 : (*[the, quick, fox, jumps]*, brown)  \n",
        "> Ex. 2 : (*[quick, brown, jumps, over]*, fox)  \n",
        "> Etc ...\n",
        "\n",
        "The neural net's task will be to predict the target word based on the context window words."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e16ca46-8d17-4917-93f9-756699d07969",
      "metadata": {
        "id": "0e16ca46-8d17-4917-93f9-756699d07969"
      },
      "source": [
        "This means we can model this problem as a classification task such that we take in the context words as our input (X) and try to predict the target word (Y) out of all the possible words in the vocabulary.  This is essentialy a *multiclass* classification task (only 1 of the possible classes is correct), where a class is equivalent to a word in the vocabulary.  Here is an overview of the process : \n",
        "\n",
        "<div style='text-align:center;'><img src=\"https://github.com/armandstrickernlp/NLP_Inalco/blob/main/Semester2/Project_sem2/CBOW_overview.png?raw=1\"/></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a4f57ea-a2eb-43f4-9f29-badef4ade538",
      "metadata": {
        "id": "0a4f57ea-a2eb-43f4-9f29-badef4ade538"
      },
      "source": [
        "## Implementing the CBOW model\n",
        "\n",
        "Using text from Shakespeare's plays, you will implement the CBOW model from scratch, using pytorch to simplify the creation of the network architecture and training loop. The implementation will be divided into 4 parts: \n",
        "* **Building the corpus Vocab**\n",
        "* **Create the (context_window, target_word) examples**\n",
        "* **Build the neural network architecture**\n",
        "* **Train the model**\n",
        "* **Visualize the word embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83df0d1b-a1ca-482a-a951-af8197f26b2d",
      "metadata": {
        "id": "83df0d1b-a1ca-482a-a951-af8197f26b2d"
      },
      "source": [
        "### 1. Building the corpus Vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b507afe8-8d4b-40f1-becb-81ee06da5c3c",
      "metadata": {
        "id": "b507afe8-8d4b-40f1-becb-81ee06da5c3c"
      },
      "source": [
        "In the next cell, the text has been loaded and split into tokens for you :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "1b1b1cf6-51a2-446f-8b4e-5a62954a8984",
      "metadata": {
        "id": "1b1b1cf6-51a2-446f-8b4e-5a62954a8984",
        "outputId": "42fb20d5-006a-4f0a-ba9e-632865790737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Number of tokens: 60933 \n",
            " First 15 tokens :  ['o', 'for', 'a', 'muse', 'of', 'fire', '.', 'that', 'would', 'ascend', 'the', 'brightest', 'heaven', 'of', 'invention']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re  \n",
        "\n",
        "\n",
        "with open('shakespeare.txt') as f:\n",
        "    text = f.read()   \n",
        "text = re.sub(r'[,!?;-]', '.',text)                                 #  Punktuations are replaced by .\n",
        "text = nltk.word_tokenize(text)                                     #  Tokenize string to words\n",
        "text = [ ch.lower() for ch in text if ch.isalpha() or ch == '.']    #  Lower case and drop non-alphabetical tokens\n",
        "print(\"Number of tokens:\", len(text), '\\n First 15 tokens : ', text[:15])  #  print data sample"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c33b36f-b63a-4127-9a07-b86284a80491",
      "metadata": {
        "id": "1c33b36f-b63a-4127-9a07-b86284a80491"
      },
      "source": [
        "Next you must :\n",
        "* Get the vocabulary and vocabulary size (the set() function can be useful...)\n",
        "* Create 2 dictionaries :\n",
        "    * word2idx => keys are words in vocab, values are a unique number you must attribute to each word\n",
        "    * idx2word => keys are a unique number, values are the corresponding word  \n",
        "    These dictionaries will allow you to map words in the vocab to unique numbers.  This is necessary as you will be feeding these numbers to the model, not the words directly.\n",
        "* Create the (context, target) example pairs and store them in a list called data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "7fd682c6-2b2c-4f8f-b951-3a7639fe3616",
      "metadata": {
        "id": "7fd682c6-2b2c-4f8f-b951-3a7639fe3616",
        "outputId": "0a3d4558-cab3-4bed-f49f-7d9efa344fd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size = 5772 (should be equal to 5775)\n"
          ]
        }
      ],
      "source": [
        "# get the vocab and vocab length \n",
        "vocab = [v for v in set(text) ]\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocab size = {vocab_size} (should be equal to 5775)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "ae6492e7-adcc-453c-a05f-6cb59688c154",
      "metadata": {
        "id": "ae6492e7-adcc-453c-a05f-6cb59688c154",
        "outputId": "f9009848-913b-4c5d-a60f-0293d715a0fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of the word 'king' :   1479\n",
            "Word which has index 250:   pirates\n"
          ]
        }
      ],
      "source": [
        "# create the word2idx and idx2word dictionaries:\n",
        "word2idx = {k:v for (v,k) in enumerate(vocab)}\n",
        "idx2word = {k:v for (k,v) in enumerate(vocab)}\n",
        "# example of word to index mapping\n",
        "print(\"Index of the word 'king' :  \",word2idx['king'] )\n",
        "print(\"Word which has index 250:  \",idx2word[5367] )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text+['','']"
      ],
      "metadata": {
        "id": "2AmTusc4Mcs4"
      },
      "id": "2AmTusc4Mcs4",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "b1eaacbd-ba33-409f-8db7-f751e8540e81",
      "metadata": {
        "tags": [],
        "id": "b1eaacbd-ba33-409f-8db7-f751e8540e81",
        "outputId": "68dfbf6e-1485-444f-f99b-ef4371177577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first 5 words : ['o', 'for', 'a', 'muse', 'of']\n",
            "example n°1 = (['o', 'for', 'muse', 'of'], 'a')\n",
            "context = ['o', 'for', 'muse', 'of']\n",
            "target = a\n",
            "Number of examples : 60929\n"
          ]
        }
      ],
      "source": [
        "# Going through the text, create a list of data examples, where each example consists of a (context, target) tuple.\n",
        "# The context can be represented as a list of the context words (2 before and 2 after)\n",
        "# You may start at word idx number 2 and end on the second to last word.\n",
        "\n",
        "data = [([a,b,d,e],c) for (a,b,c,d,e) in zip(*[text[i:] for i in range(5)])]\n",
        "\n",
        "# loop to make training examples\n",
        "...\n",
        "\n",
        "\n",
        "# check if it works for the first example   \n",
        "print(f'first 5 words : {text[:5]}')\n",
        "print(f'example n°1 = {data[0]}')\n",
        "print(f'context = {data[0][0]}')\n",
        "print(f'target = {data[0][1]}')\n",
        "\n",
        "print(f'Number of examples : {len(data)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,d in enumerate(data):\n",
        "  if 'm' in d:\n",
        "    print(d,i)"
      ],
      "metadata": {
        "id": "COu1yU2UKWfh"
      },
      "id": "COu1yU2UKWfh",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cda9daac-b340-4b08-84d1-785299dd5958",
      "metadata": {
        "id": "cda9daac-b340-4b08-84d1-785299dd5958"
      },
      "source": [
        "Expected output is :\n",
        "first 5 words : ['o', 'for', 'a', 'muse', 'of']  \n",
        "example n°1 = (['o', 'for', 'muse', 'of'], 'a')  \n",
        "context = ['o', 'for', 'muse', 'of']  \n",
        "target = a  \n",
        "Number of examples : 60972"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec393b3-ece5-4da9-8cc5-b0441d607c19",
      "metadata": {
        "id": "2ec393b3-ece5-4da9-8cc5-b0441d607c19"
      },
      "source": [
        "### 2. Building the neural net architecture with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "ac619996-e928-4a40-8d84-2978df3ca21f",
      "metadata": {
        "id": "ac619996-e928-4a40-8d84-2978df3ca21f"
      },
      "outputs": [],
      "source": [
        "# https://pytorch.org/get-started/locally/ to see how to install pytorch if you\n",
        "# are working on your own computer\n",
        "# however using googlecolab might be easier\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "791fadcc-bc27-4bce-af1e-2c3e3d85a591",
      "metadata": {
        "id": "791fadcc-bc27-4bce-af1e-2c3e3d85a591"
      },
      "source": [
        "#### 2.1 Batching the data examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f8713d6-abf0-4785-b902-3bfb9bf2828a",
      "metadata": {
        "id": "0f8713d6-abf0-4785-b902-3bfb9bf2828a"
      },
      "source": [
        "In order to accelerate the training process, we can **batch** training examples together.  This means that instead of feeding the model 1 example at a time, we feed it 16 or 32 or 64 or 128 in one go.  Pytorch's `Dataloader`class takes care of this for you.  It takes as arguments a pytorch `Dataset`(`TensorDataset` in this case) and a `batch_size`.  \n",
        "To be instantiated, the `TensorDataset` class needs a pytorch tensor (`torch.tensor(listOfValues)`) of inputs and targets as arguments.  In this case you will need to create a tensor of contexts, where 1 context has to be a list of indices corresponding to the context words, and a tensor of targets, where the target words are also respresented by their idx.  Use the word2idx dictionary and data list you created previously."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[  word2idx[trg] for _,trg in data]"
      ],
      "metadata": {
        "id": "Fz7h_7MdOIFR"
      },
      "id": "Fz7h_7MdOIFR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "40663d34-8ccd-47df-996f-a77341c3c1d0",
      "metadata": {
        "id": "40663d34-8ccd-47df-996f-a77341c3c1d0"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "contexts = torch.Tensor([ list(map(lambda x : word2idx[x], ctx)) for ctx,_ in data])\n",
        "targets = torch.Tensor([ word2idx[trg] for _,trg in data])\n",
        "\n",
        "assert len(contexts) == len(targets)\n",
        "\n",
        "dataset = TensorDataset(contexts, targets)\n",
        "dataloader = DataLoader(dataset, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "7aa3aae6-2d8b-4c50-8826-fa2d69f3a755",
      "metadata": {
        "id": "7aa3aae6-2d8b-4c50-8826-fa2d69f3a755",
        "outputId": "73ccd95d-ea6d-457d-8f0a-9c7b79eda5ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60929, 4])\n",
            "tensor([[5366., 2781., 5625., 1972.],\n",
            "        [2781.,  776., 1972., 3069.]])\n",
            "tensor([ 776., 5625.])\n"
          ]
        }
      ],
      "source": [
        "print(contexts.shape)\n",
        "print(contexts[:2])\n",
        "print(targets[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1271674-999e-4b20-a028-b336c336769a",
      "metadata": {
        "id": "a1271674-999e-4b20-a028-b336c336769a"
      },
      "source": [
        "Expected output should look similar to this (the indexes may not be the same):  \n",
        "\n",
        "torch.Size([60972, 4])  \n",
        "tensor([[ 441, 1818, 3263, 3379],\n",
        "        [1818, 5013, 3379, 1883]])  \n",
        "tensor([5013, 3263])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bceefc1f-fd2f-45b0-813a-ae93d8f33ff1",
      "metadata": {
        "id": "bceefc1f-fd2f-45b0-813a-ae93d8f33ff1"
      },
      "source": [
        "#### 2.2 The Model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f70a4d-8799-465c-8922-5698630f3995",
      "metadata": {
        "id": "97f70a4d-8799-465c-8922-5698630f3995"
      },
      "source": [
        "Here is an overview of the model's architecture and how a single example flows through the layers :  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "155fef6b-8fe4-4466-a7c6-5fbb1b2e7e18",
      "metadata": {
        "id": "155fef6b-8fe4-4466-a7c6-5fbb1b2e7e18"
      },
      "source": [
        "<div style='text-align:center;'/><img src='https://github.com/armandstrickernlp/NLP_Inalco/blob/main/Semester2/Project_sem2/Model_architecture.png?raw=1'>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b66c5284-faed-47df-8d0a-7ef60c98a389",
      "metadata": {
        "id": "b66c5284-faed-47df-8d0a-7ef60c98a389"
      },
      "source": [
        "Take a look at the XOR notebook to see how a model class is created in pytorch (how it subclasses nn.Module and the init function especially).\n",
        "\n",
        "You may add the `vocab_size` and number of embedding dimensions (`embedding_dim`) you want your embeddings to have (50 is a good choice) to the init parameters, so as to pass them in when you instantiate the model. \n",
        "\n",
        "Pytorch allows you to implement a special layer, called an embedding layer (`nn.Embedding`), which precisely serves the purpose of allowing you to train embeddings when training a model. Look at the the documentation to see what this layer takes as inputs : https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
        "\n",
        "Then, add an output layer.  Be aware of the input and output sizes of the layer...  Take a look at the notebook on the XOR problem to see how to create a linear layer in pytorch.\n",
        "\n",
        "The `forward` function is the one that deals with the flow of data through the model.  In this case, it takes as input a *batch* of context vectors.\n",
        "This batch must first go through the embedding layer which returns 4 vectors (1 for each word) of equal dimension for each example in the batch.  \n",
        "If you have chosen a batch size of 128 and an embedding dimension of 50, then the output shape of the `nn.Embedding` layer will be:  (128, 4, 50):  128 matrices (one per example in the batch) of 4 by 50 (one 50 dimensional vector per context word).\n",
        "\n",
        "\n",
        "For each example in the batch, you will average these 4 vectors in order to obtain a single vector.  This means you must specifiy that the mean calculated has to be along dimension 1 (the one equal to 4).  This is why the model is called Continuous Bag of Words: we don’t really consider the order of the context words when averaging them...  So that information is lost.\n",
        "\n",
        "Then, all that is left is to pass the batch of averaged vectors to the output layer !\n",
        "\n",
        "No need to use the softmax function as a final activation function here, as this will be done automatically by the loss function in the training loop (cf. section 2.4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe1dfcc6-3695-442f-921f-fc8dcbef10f3",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "fe1dfcc6-3695-442f-921f-fc8dcbef10f3",
        "outputId": "1e3f7fc7-0bf0-4712-afd1-73d3c33dcfa0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name '____' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the Neural Net\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCBOW\u001b[39;00m(\u001b[43m____\u001b[49m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ___, ____):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# inherit from nn.Module's init function\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         \n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# embedding layer\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
          ]
        }
      ],
      "source": [
        "# Create the Neural Net\n",
        "\n",
        "class CBOW(____):\n",
        "    def __init__(self, ___, ____):\n",
        "        ...\n",
        "        \n",
        "\n",
        "    def forward(self, batch):\n",
        "        ...\n",
        "        # get the embeddings from the Embedding layer and average them along dim=1.\n",
        "        # use .shape to see what shape the batch has before and after going through \n",
        "        # each layer if you need to\n",
        "        \n",
        "       \n",
        "        # pass the batch through the output layer to get the logits\n",
        "        # the output should be a matrix with dimensions batch_size x vocab_size\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b56d320-7eba-4130-af1e-6224784cc9d1",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "4b56d320-7eba-4130-af1e-6224784cc9d1",
        "outputId": "f588210d-08a3-464c-b578-e960833e17bf"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'CBOW' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#instantiate the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCBOW\u001b[49m(vocab_size, \n\u001b[1;32m      6\u001b[0m              embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CBOW' is not defined"
          ]
        }
      ],
      "source": [
        "# set random seed \n",
        "torch.manual_seed(42)\n",
        "\n",
        "#instantiate the model\n",
        "model = CBOW(vocab_size, \n",
        "             embedding_dim=50)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e37598e-f290-4b7c-b884-3b83cb2f4321",
      "metadata": {
        "id": "3e37598e-f290-4b7c-b884-3b83cb2f4321"
      },
      "source": [
        "Your model should look something like this :\n",
        "\n",
        "CBOW(  \n",
        "    (embeddings): Embedding(5775, 50)   \n",
        "    (output): Linear(in_features=50, out_features=5775, bias=True)  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fff8ba7-4287-4ef9-83c3-0d5d078fa26b",
      "metadata": {
        "id": "6fff8ba7-4287-4ef9-83c3-0d5d078fa26b"
      },
      "source": [
        "#### 2.3 Visualizing word vectors before training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50af9d26-23af-47e7-9879-92c2a9a1816c",
      "metadata": {
        "id": "50af9d26-23af-47e7-9879-92c2a9a1816c"
      },
      "source": [
        "To see if the model has had any effect on the word vectors (which are randomly initialized when you instantiate the model), it can be useful to compare the vectors for certain words before vs. after training.  In order to plot and visualize the vectors in 2D, we must however use an algorithm called *Principal Component Analysis (PCA)* to reduce the vectors' dimensions down to 2.  This can be easily done using `sklearn`.  \n",
        "\n",
        "In the cell below, you have a list of words which you can modifiy as you wish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1120dd2-0adc-497a-842f-24dbdbe1ecad",
      "metadata": {
        "id": "d1120dd2-0adc-497a-842f-24dbdbe1ecad",
        "outputId": "f6173355-bbb4-46fc-e341-6275b47e148d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.0064013  4.596994 ]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# list of words to study\n",
        "words = ['man', 'woman', 'lord', 'lady', 'king', 'queen', 'her', 'him', 'he', 'she']\n",
        "\n",
        "# the embeddings for the words, randomly initialized by the model\n",
        "embeddings = np.array([model.embeddings(torch.tensor(word2idx[word],dtype=torch.long)).detach().numpy() \n",
        "                       for word in words]).squeeze()\n",
        "\n",
        "# perform PCA (reduce to 2 dimensions)\n",
        "pca = PCA(n_components=2)\n",
        "reduced = pca.fit_transform(embeddings)\n",
        "\n",
        "# get the 2D embedding reduction for the first word in the list, to track after training\n",
        "print(reduced[0])\n",
        "\n",
        "# plotting the 2D vectors\n",
        "pyplot.scatter(reduced[:,1], reduced[:, 0])\n",
        "for i, word in enumerate(words):\n",
        "    pyplot.annotate(word, xy=(reduced[i, 1], reduced[i, 0]))\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf2e7021-d626-4120-b783-34763c8c082f",
      "metadata": {
        "id": "bf2e7021-d626-4120-b783-34763c8c082f"
      },
      "source": [
        "#### **Question** : \n",
        "\n",
        "How would you expect the vectors to move ?  Which word vectors should end up closer ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f759c59f-e064-4d7d-8da0-1ffa743e1c4b",
      "metadata": {
        "id": "f759c59f-e064-4d7d-8da0-1ffa743e1c4b"
      },
      "source": [
        "#### 2.4 Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1449c12b-df5c-484e-8596-c75d2df88b91",
      "metadata": {
        "id": "1449c12b-df5c-484e-8596-c75d2df88b91"
      },
      "source": [
        "Start by selecting the appropriate loss function and optimizer.  You may use `nn.CrossEntropyLoss()` as a loss function and `torch.optim.SGD`for the optimizer.  This optimizer is an implementation of the Gradient Descent algorithm and takes as arguments `model.parameters()`, the model's parameters, and `lr` the learning rate, which can be set to 0.03 when using batches of 128 (you may tru different values).  \n",
        "\n",
        "Next you can run the model for 150-200 epochs.  This should be able to run on your computer, but if not just copy paste all of the cells into a colab notebook.  The fact that we divided the training data into batches means each epoch should take approx. 10 secs instead of several minutes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a08957-edaf-4501-a939-5254f62ee363",
      "metadata": {
        "tags": [],
        "id": "06a08957-edaf-4501-a939-5254f62ee363",
        "outputId": "5c738930-1399-44a8-dcf6-4b62c337f3eb"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataloader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# the dataloader is a generator object, it produces a batch of contexts and targets if you iterate over it.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m context, target \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader\u001b[49m:\n\u001b[1;32m     16\u001b[0m     \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# get the logits\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# calculate the loss by passing the logits and targets to the loss_function\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
          ]
        }
      ],
      "source": [
        "import time\n",
        "loss_function = None\n",
        "optimizer = None\n",
        "\n",
        "#TRAINING\n",
        "# a few seconds per epoch\n",
        "# you can track the time passed per epoch by decommenting the time1 line and the print(time.time...) at the end.\n",
        "for epoch in range(150):\n",
        "    #time1 = time.time()\n",
        "    \n",
        "    # initiliaze the total_loss for each epoch to 0\n",
        "    total_loss = None\n",
        "\n",
        "    # the dataloader is a generator object, it produces a batch of contexts and targets if you iterate over it.\n",
        "    for context, target in dataloader:\n",
        "        \n",
        "        # get the logits\n",
        "        logits = None\n",
        "        \n",
        "        # calculate the loss by passing the logits and targets to the loss_function\n",
        "        loss = None\n",
        "        \n",
        "        # add the loss value to the total_loss (use loss.item() to get only the value)\n",
        "        total_loss += None\n",
        "\n",
        "        \n",
        "        # optimize the network using the three steps seen in the XOR notebook\n",
        "        ...\n",
        "    \n",
        "    # track the loss by printing it every 10 epochs\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1} : {total_loss}')\n",
        "    \n",
        "    #print(time.time()-time1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5324aef8-3f6a-41fc-badd-9357670650c8",
      "metadata": {
        "id": "5324aef8-3f6a-41fc-badd-9357670650c8"
      },
      "source": [
        "#### 2.5 Visualizing word vectors before training\n",
        "\n",
        "Using the same list of words as before, the next cell plots the new word vectors.  What has changed ? Do the results seem to verify your hypotheses ?  \n",
        "How do you think the results could be improved ?\n",
        "\n",
        "You can try changing the hyperparameters to see if they have any impact.  These include :\n",
        "* batch size\n",
        "* number of embedding dimensions\n",
        "* learning rate\n",
        "* number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22e90dfa-1fdb-4d1d-9aae-e38b7258d5b0",
      "metadata": {
        "id": "22e90dfa-1fdb-4d1d-9aae-e38b7258d5b0",
        "outputId": "8c6f16e8-3784-4a58-bf95-0e56c658bbfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.0064013  4.596994 ]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "embeddings = np.array([model.embeddings(torch.tensor(word2idx[word],dtype=torch.long)).detach().numpy() \n",
        "                       for word in words]).squeeze()\n",
        "\n",
        "reduced = pca.fit_transform(embeddings)\n",
        "print(reduced[0])\n",
        "\n",
        "pyplot.scatter(reduced[:,1], reduced[:, 0])\n",
        "for i, word in enumerate(words):\n",
        "    pyplot.annotate(word, xy=(reduced[i, 1], reduced[i, 0]))\n",
        "pyplot.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "Word2Vec_Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}